Title: Optimized computational modeling of adaptive activation-based concept learning



1. Introduction
    (REDO)
    Technology has made its way into our working environments, vehicles, mobile phones and even into our homes, in an attempt to make our lives easier and more convenient. One area of our lives, where technology has been gaining popularity is education. Educational technology in particular has been gaining increasing popularity due to its efforts in improving the application of technology in facilitating learning.
    Learning words in languages = very important, declarative memory? A language user's mother tongue is learned at a very young age when not much conscious effort is put into the learning process, but instead the learner acquires the language unconsciously therefore that is referred to as "language acquisition". On the other hand when it comes to learning further foreign languages, the user has to actively participate in the learning process in which case we speak of "language learning".
    Cognitive psychology has been able to identify a number of patterns, called cognitive biases, which try to explain how humans process information, such as the modality effect, the testing effect and the spacing effect. While being aware of these patterns allows educators to simply develop systems, which reliably produce improved learning results, computers require well defined and formalized rules in order to achieve this. One of the more famous and successful cognitive architectures is the Adaptive Control of Thought—Rational (known as ACT-R).
    The goal of this thesis is to analyze an adaptive activation-based learning model, based on the ACT-R architecture and try to develop a more computationally efficient implementation of that model. I will compare the performance as well as the accuracy of the resulting implementation to the original implementation of the model.



2. Background
    SUBSECTION: The spacing and testing effects
    When it comes to factual learning tasks, massed learning (colloquially known as cramming) has become the go-to approach. It consists of exposing the learner to a big amount of information for a short amount of time in an attempt to prepare the learner for an upcoming examination on the studied material. Research, however, has shown (Ebbinghaus, 1885) that massed learning only produces short-term results and therefore is unsuitable when we want to achieve long-term information retention. The proposed alternative for effective long-term results is the so-called distributed (or spaced) learning, which is based on Ebbinghaus' conclusions that spacing the individual item *{ASTERISK: I will use the terms "vocabulary item" and "word" interchangeably from now on} interactions further apart actually produces consistent long-term retention. This discovery is known as the "spacing effect". Furthermore, spaced learning attempts to optimize both intra-session intervals (how often each word gets presented within a study session) and inter-session intervals (how far apart different study sessions should take place).

    SUBSECTION: The basics of ACT-R
    Since the model, which is being analyzed in this thesis is based on the ACT-R cognitive architecture, I will provide a very superficial introduction to it in order to introduce some important terminology and concepts. ACT-R stands for "Adaptive Character of Thought - Rational" and its aim is to explain and formally define how humans perceive and express both declarative and procedural knowledge. Declarative knowledge refers to the ability of the human brain to retrieve <BOLD factual information BOLD>, whereas procedural knowledge is connected to the subconscious ability to accomplish somewhat <BOLD complex procedures BOLD> (riding a bicycle, going up the stairs, writing a text etc.). Since vocabulary learning can be compared to learning facts, the model described in this thesis will make use of the implementation of declarative memory in the ACT-R architecture. The model is also referred to as an activation-based one, as it relies on the concept of "activations", which ACT-R uses in order to represent how strongly each vocabulary item is embedded into memory. {Reference: van Woundenberg 2008}.

    SUBSECTION: The Pavlik and Anderson model
    Pavlik and Anderson have managed to formalize this research into their model by modifying the base ACT-R formula for calculating activations. An item's activation is expressed as a power function of the sum of the time deltas of its previous encounters (how long ago each encounter occured), scaled by the rate of decay at the given encounter (how fast the activation decays with the passage of time). This results in the latest encounters having the highest impact on the item's current activation *{ASTERISK: what is a word encounter??? (word-pair, sentence with missing word, etc.)}.
    Formula 1.0 shows the equation developed by Pavlik and Anderson for calculating the activation of an item at a given time <ITALIC t ITALIC>. 
    Formula 1.0: <ACTIVATION CALCULATION FORMULA>

    \\ TODO: think about providing a graph of what the activations should look like when explaining what an activation is

    The variables in this formula are defined as follows:
    - mi   = the activation of the current item
    - t    = a given timestamp
    - tj   = the timestamp of a previous encounter with the item (note that tj is always smaller than t)
    - di,j = the rate of activation decay of item i at encounter j
    The rate of decay for the current encounter is calculated by taking into account the activation of the item at the previous encounter:
    Formula 1.1: <DECAY CALCULATION FORMULA>
    If a previous encounter happened when the item's activation was high, this would also produce a high rate of decay, which when plugged into the activation formula would further scale down the time difference, resulting in a smaller contribution of that encounter to the current activation of the item (meaning that being presented with a recently encountered item has little effect when it comes to strenghtening that item in memory). Decay can further be modified using the other two variables seen in the formula. The <ITALIC c ITALIC> parameter represents a scaling factor, which governs how strong the spacing effect is and the <ITALIC ALPHA ITALIC> parameter represents the lowest possible decay value (usually 0.5 since that is the default decay value in ACT-R). The formula recurses down for each previous encounter and the base case for each item occurs when the activation is being calculated for a time <ITALIC t ITALIC> when there are no previous encounters. In that case the result is an activation of negative infinity (-INF), since the item has never been encountered before and therefore has no strength whatsoever in the learner's memory. If decay is being calculated for an activation of -INF, this results in the default decay value.
    Having calculated the activations of all items in the current vocabulary list at the current time, the model decides which item to present next based on the internal logic shown in Figure 1.
    The model achieves adaptability by tweaking the <ITALIC ALPHA ITALIC> parameter <ITALIC ALPHA ITALIC> based on the learner's performance. Correctly guessing a word during one of the encounters means that the learner is making progress in strenghtening that word's activation in their memory. In that case the <ITALIC ALPHA ITALIC> gets reduced, which results in a lower decay and therefore the item is shown less often during the study session. If the reverse is the case (the learner gets the word wrong), then they need to practice it more in order to learn it better. To make sure this happens, the model increases the <ITALIC ALPHA ITALIC>, which in turn increases the decay and results in more frequent presentations. Furthermore, the model tries to present words before they fall below a forgetting threshold <BOLD tau BOLD>, at which point they would be forgotten by the user and previous learning will have been in vain. After a state is reached, where the decay is so minimal that the item's strength in memory is considered stable, the item stops being presented (and is considered "learned") and a new item from the vocabulary list enters the system.

    SUBSECTION: Enhancements of the Pavlik and Anderson Model
    The Pavlik and Anderson model has been used as a basis for a lot of the research which targets vocabulary learning (and factual learning in general). Extensions to the model have been made by Pavlik (2007); Van Rijn, Van Maanen, and Van Woudenberg, 2009; Nijboer 2011 and others. All of the proposed extensions keep the general idea of the model, but aim to improve the activation calculation to either better represent the learner or better show human learning and cognitive patterns.
    In 2007 Pavlik suggested an improvement to the activation formula by adding 3 additional <ITALIC BETA ITALIC> parameters (Formula 2.0). Each of those parameters would contain either item-specific or learner-specific information, which would better represent the learner's connection to the particular item. Since different people learn at different rates, the <ITALIC BETAs ITALIC> parameter was added in order to introduce the learner's learning ability to the activation calculation. In addition to that, certain words are more difficult to learn than others (either because of their morphology or their semantics). To account for that, Pavlik added the <ITALIC BETAi ITALIC> parameter to the formula as well. The first two parameters are then combined in the <ITALIC BETAs,i ITALIC> parameter in order to represent the relative difficulty of a given item for the particular learner. To add an additional dimension to the calculation, the <ITALIC bj ITALIC> parameter was added, which allows the system to apply scaling to different word presentations. Meaning that it can now evaluate word-pair presentations differently than presentations of the word in context, which allows for much more control over the learning process.
    Formula 2.0: <ACTIVATION CALCULATION + BETA PARAMS>
    Different approaches were taken by Van Rijn, Van Maanen, Van Woudenberg in 2009 and Nijboer in 2011. They proposed that the learner's reaction time be recorded and used when calculating the activation of each item. This suggestion is based on the idea that if the learner takes longer to finish the word encounter, then it is more difficult for them to recall the item from memory. Nijboer further expanded upon the idea of using reaction time by providing a way to predict the expected time needed to process the item presentation exercise (for example the time needed to read a sentence, before the learner has to attempt to retrieve a missing word from their memory).

    SUBSECTION: The problem
    Even though most of the proposed extensions have been shown to provide improved effectiveness of the model, none of them tackle the problem of computational efficiency. When integrated in a real-life system, an inefficient algorithm could inconvenience the user by making them wait while the activations of all items are calculated before each encounter, wasting precious learning time during the study sessions. Furthermore, since the activation calculation takes into account all previous encounters with the item, it becomes increasingly expensive when it comes to learning more difficult words (since they would take more encounters to learn). All of these factors have inspired this attempt at improving the computation time of the algorithm.

    SUBSECTION: Program optimization methods
    The process of algorithm optimization usually aims to improve an algorithm by reducing the usage of a certain resource (whether it is execution time, hard drive space or another available resource). However, sometimes optimization with regards to one resource requires increased usage of another one. In the case of this learning algorithm, the valued resource is execution time (since the algorithm is executed before each item encounter and needs to quickly determine which word should be presented next).
    Program optimization is usually applied using established and proven methods. Those methods differ in the level at which the optimization occurs, as well as in the type of optimization problem they are trying to solve. The different levels of program optimization include:
    1. Optimal choice of technologies
    2. Algorithm design with attention to resource efficiency
    3. Writing source code with attention to efficient command execution
    4. Compiler optimizations
    The higher levels of optimization (where most of the work is usually done by the developer instead of the computer) tend to have a greater impact on program efficiency than the lower ones. This means that an inefficient algorithm, which was run on a highly optimized system will execute slower than an efficient algorithm, which was run on a sub-optimal system. Therefore the higher levels are usually targeted first when an optimization problem occurs.
    
    Some of the most famous optimization methods make use of recursion in order to simplify the initial problem into smaller, more manageable sub-problems. One such method is the well known <ITALIC Divide and conquer ITALIC>, which splits the initial problem recursively until the sub-problems are simple enough to be easily solved. After the base problems are solved, their solutions are combined in a way that yields the solution to the initial problem. Divide and conquer algorithms have found a wide usage from sorting problems to syntactic analysis problems {Reference: Thomas H. Cormen, Charles E. Leiserson, and Ronald L. Rivest, Introduction to Algorithms (MIT Press, 2000)}. Another optimization technique, which tries to optimize recursively solvable problems is <ITALIC Dynamic programming ITALIC>.
    While Divide and conquer is only suitable for problems, where the merging of the solutions to the recursively created sub-problems yields the result of the original problem, Dynamic programming is used in cases, where those solutions can be directly used to solve the original problem. The applicability of Dynamic programming techniques to the problem at hand depends on 2 properties: optimal substructure and overlapping sub-problems. Optimal substructure is fulfilled when an optimal solution to the problem contains optimal solutions to its sub-problems {ASTERISK: notice that when talking about optimization, there is no single optimal solution, there are multiple possible ones}. The other property of Dynamic programming refers to the fact that problems, to which it is applied do not constantly generate new sub-problems at each step (which is what Divide and conquer algorithms tend to do), but instead repeatedly solve the same problems. Since this repeated solving is very inefficient, Dynamic programming promotes the use of <ITALIC Memoization ITALIC> in order to store the results of sub-problems in a map so that the algorithm doesn't need to re-solve them every time they come up, but instead just fetch the solution from memory {Reference: Thomas H. Cormen, Charles E. Leiserson, and Ronald L. Rivest, Introduction to Algorithms (MIT Press, 2000)}.
    An example of a problem, to which Dynamic programming could be applied is generating a number from the Fibonacci sequence. This problem exhibits both optimal substructure (since each number is a result of summing all previous numbers) and overlapping sub-problems (calculating each number requires the calculating of all previous ones, which inevitably makes some of the calculations overlap). Other uses can be found in problems such as finding the shortest path, levenstein distance calcualation as well as parsing (The Earley chart parser). The activation calculation of Pavlik and Anderson's learning model, however, behaves in the same way that the Fibonacci sequence is calculated: in order to get the activation of an item at an encounter with a given time <ITALIC t ITALIC>, we need to calculate the activations of that item at all encounters, which occured before the given one. Once the calculation recurses down, it causes a lot of the values to be recalculated and therefore using Dynamic programming techniques (in particular Memoization), could speed up the calculation and make it less demanding. Of course storing each word's activation for each encounter requires the usage of more hard drive space, but the size of this information should be small enough to justify the undeniable improvement in performance.

    Another approach to optimization can be observed in Approximate Computing, which uses result accuracy as an available resource. This method is based on the idea that solving a problem, the accurate calculation of which proves to be quite resource-intensive, by instead approximating the result (within a limited range of error), provides an unexpected improvement in performance. Since result approximation can have catastrophic consequences if applied improperly, Approximate Computing follows certain rules about which data can be approximated and which - not. Understanding that only data, which is not critical to the execution of the program, can be approximated, it is up to the developer to decide (and prove) that even after applying this method, the program still provides results, which are expected by the user {Reference: S. Mittal, “A Survey Of Techniques for Approximate Computing”, 20xx. ACM Comput. Surv. a, b, Article 1 (2015)}.

    // TODO: add more references to linguistic papers


3. The optimization process
    SUBSECTION: Naive implementation
    In its most inefficient form, the activation calculation algorithm is a mutual recursion between the activation function and the decay function. The activation function depends on two sets of values: the timestamps of all encounters with a given item and the item's decay rate at each of those encounters. While encounter timestamps are most likely already stored in each item's encounter history, calculating the decay proves a little bit more intricate. The item's decay intercept (<ITALIC ALPHA ITALIC>) is easily accessible, but calculating the activation of the previous encounter requires multiple recursive calls of the two functions until no more previous encounters exist. Although this is inefficient, it should still function when the number of encounters isn't that big, but once an item has been encountered a certain number of times, the continuous mutually recursive calls overflow the stack. An obvious solution would be to simply store the activation value for each encounter (since a history of encounters is already being maintained) and then simply retrieve them whenever the decay rate needs to be calculated for a certain encounter. This, however, is impossible due to the fact that the model adjusts based on the user's performance. As already mentioned, the model adjusts its representation of the user and their interaction with each item by tweaking the item's <ITALIC ALPHA ITALIC> value, which directly affects its decay rate and hence how frequently it is chosen for the next encounter. This results in the <ITALIC ALPHA ITALIC> value indirectly influencing the very activation of the item after each encounter. Since the activation value is constantly changing, retrieving it from memory at different times could produce invalid results.

    SUBSECTION: Base implementation
    To avoid the above scenario, it is more sensible to implement the algorithm in such a way, that recursion only occurs in the activation function. The purpose of recursing then is to calculate the activation of the previous encounter and once that is achieved, the value can be used for directly calculating the encounter's rate of decay. Although this solves the stack overflow problem, it is still a very inefficient solution with an exponential complexity. Since the activation function is recursively called <FORMULA 2^n FORMULA> times, where <ITALIC n ITALIC> is the number of encounters in the item's encounter history, the algorithm will perform worse as the encounter histories of all items grow. A closer inspection of the algorithm shows that the bottleneck occurs because of the number of function calls, which are executed with the same parameters. The reason for this is that calculating the activation of an item at the current encounter requires the activations of all previous encounters with the item to also be calculated. Recursing down, this results in the activations of earlier encounters being recalculated multiple times, because they are all (even though sometimes indirectly) needed for calculating the activations of later encounters. For example if an item has only been encountered 3 times, calculating its activation at encounter 4 requires recursive calls to activations 3, 2 and 1, each of which also requires recursive calls to their previous encounters. In the end the activation of encounter 1 ends up being calculated 4 times and the whole process makes a total of 8 recursive function calls.
    This behavior can also be observed when trying to generate a number from the Fibonacci sequence, since each number is the sum of all previous ones. Given that a more efficient implementation of the Fibonacci algorithm can be achieved by applying dynamic programming techniques and the fact that the activation algorithm fulfills both requirements for being able to use dynamic programming (the identical recursive calls prove that the activation algorithm includes overlapping sub-problems and the fact that each activation is dependent on all previous ones shows the optimal substructure of the algorithm), it is reasonable to attempt to apply dynamic programming to the activation calculation as well. This is achieved by caching the results of successfully executed recursive calls so that whenever the activation function needs to be executed with the same parameters, the result is simply retrieved from memory. Making use of this technique drastically decreases the time complexity of the algorithm from exponential to linear and speeds up the calculation. Instead of <FORMULA 2^n FORMULA> recursive calls (where n is the number of times the item has been encountered), the algorithm now only makes <FORMULA n+1 FORMULA> calls (one for each previous encounter and one for the current one).

    SUBSECTION: Heuristic approach
    Despite the fact that the implementation described above significantly speeds up the calculation, the facts that this calculation occurs for each word, before each item encounter and that it becomes more taxing as the number of encounters increases could require that it be further optimized in order to not hinder user interaction when faced with more difficult words or longer word lists. It is impossible to make further significant improvements to the time complexity of the actual activation calculation algorithm, but it is feasible to reduce the amount of calculations, done during the study session by making use of the time between sessions.
    There are two reasons why the recursive calculation needs to take place before each item encounter:
    1. The time, elapsed since the last encounter of each item affects the item's current activation
    2. The <ITALIC ALPHA ITALIC> value of each item is adjusted after each encounter in order for the model to adapt to each learner
    Although the elapsed time cannot be ignored, since it represents the spacing effect, it might be possible to make use of the changes in the items' <ITALIC ALPHA ITALIC> values when further optimizing the algorithm. In his PhD Thesis, Florian Sense shows that an individual's rate of forgetting (<ITALIC ALPHA ITALIC>) stays relatively stable over time {Reference: Sense, F. (2017). Making the most of human memory: Studies on personalized fact-learning and visual working memory [Groningen]: University of Groningen}. This information, combined with the experience of Approximate computing, can be utilized to develop a heuristic solution for faster activation calculations.
    As mentioned above, the values around which the heuristic solution is built are the items' rates of forgetting (<ITALIC ALPHA ITALIC>). Since those values are adjusted based on the outcomes of each user interaction with each item and since it is impossible to predict the outcomes in advance, no true approximation can be made. Instead, this approach is based on caching the activation values of all previous encounters and then using the cached values whenever the current activation needs to be calculated, which results in each activation calculation requiring a single function call. Even though this means that the previous activations don't get recalculated with the newest <ITALIC ALPHA ITALIC>, its stable rate of change should ensure that no substantial differences occur between the actual updated activation values and the cached ones. That being said, if the previous activations are never updated, they run the risk of becoming outdated once the difference between the current <ITALIC ALPHA ITALIC> and the <ITALIC ALPHA ITALIC>, which was used for calculating a previous encounter's activation, becomes significant enough. To prevent this from happening, the model should perform a complete update of the cached activations, which consists of recalculating the activations of all previous item encounters using the item's current <ITALIC ALPHA ITALIC> value. Since the goal is to avoid wasting time during study sessions, this update should take place between them, which preservers the user's interaction with the system during the actual process of studying.
    // TODO: approximation error is controlled by updating the cache


4. Evaluation of Performance (Setup + Results)
    SUBSECTION: Simulation setup
    All experiments conducted in order to research the spacing effect in vocabulary learning systems use different parameters for their learning model (study session duration, time between study sessions, vocabulary size, etc.). The reason for this is because learner performance largely differs based on internal factors, such as the learner's language learning capabilities, their familiarity with the domain, in which particular words are used and other, which makes coming up with the perfect set of parameters a challenge {Reference: van Woundenberg 2008}. In order to provide a stable environment, which allows for comparison between the results of the different experiments, I have chosen to conduct simulations based on those in Christopher Dilley's Paper on the "Application of Personalized Adaptive Learner Modeling to Vocabulary Learning Software" {Reference: Chris' thesis}.
    The experiments simulate a learning process, which consists of 2 study sessions, each lasting 30 minutes and taking place 24 hours apart. These values should allow for testing of the spacing effect not only during study sessions, but also in the time between them. The goal of the simulations is to replicate the process of a human learner being presented with a list of 37 words during the specified studying time. The simulation system keeps track of two sets of <ITALIC ALPHA ITALIC> values for each word:
    - Real <ITALIC ALPHA ITALIC>: randomly assigned to each word before the simulation in order to show how difficult that word is to learn
    - Predicted <ITALIC ALPHA ITALIC>: adjusted based on word interaction outcomes as a way of simulating the model's adaptability (starts at a default vaule of 0.3)
    At each word encounter, a learner's response is simulated by calculating the probability of them being correct, which is based on the item's activation with respect to its Real <ITALIC ALPHA ITALIC> (Formula 3.0). The probability is then used to simulate a loaded coin flip (Formula 3.1), which generates either a correct or an incorrect response. Depending on the simulated response, the model adjusts the Predicted alpha in order to reflect whether the word is being learned. If the response was correct, the item's Predicted <ITALIC ALPHA ITALIC> gets reduced by a certain amount, which results in a lower rate of decay for the item's activation and therefore causes the item to occur less often during study sessions. On the other hand, if the simulated response was incorrect, the Predicted <ITALIC ALPHA ITALIC> is increased by a certain amount, increasing the item's activation decay and causing the item to be shown more often during studying. Sometimes the simulated item interaction produces a result, which only requires a slight adjustment of the Predicted <ITALIC ALPHA ITALIC>, which is reflected in formulas 3.2_a and 3.3_b. Producing expected results (a correct response when the recall probability is very high and an incorrect one when it is very low) means that the model already represents the learner's knowledge of the word correctly and therefore its <ITALIC ALPHA ITALIC> only needs a slight adjustment in order to include the outcome of the interaction. Producing the opposite outcomes (a correct answer when the recall probability is very low and an incorrect one when it is very high) means that the model's prediction of the item's alpha is incorrect and therefore needs to be adjusted more significantly in order to account for the user's progress or regress with respect to learning the particular item.

    Formula 3.0: Calculating the recall probability of an item, based on its activation
    Formula 3.1: Simulating a loaded coin flip
    Formula 3.2_a: Adjusting the <ITALIC ALPHA ITALIC> when a correct answer is given
    Formula 3.2_b: Adjusting the <ITALIC ALPHA ITALIC> when an incorrect answer is given

    SUBSECTION: Evaluation of performance
    In order to evaluate the progress of the algorithm optimization process, I tracked the duration of the simulations as a measure of how fast the activation computations took place and the average <ITALIC ALPHA ITALIC> errors as a measure of how accurately the model adapts to the user's performance. Since the simulations do not require actual user interaction with the words, they track the duration of word encounters and study sessions by using an internal clock. This means that the most time during a simulation is spent on the process of calculating item activations when choosing the next item to be presented, which makes the duration a suitable measure of the calculation's performance. However, due to the use of random number generation when assigning the Real <ITALIC ALPHA ITALIC>s of each item, as well as when simulating the learner's response, I have taken the average duration of 50 simulations. Keeping in mind that the model's goal is to adjust each item's Predicted <ITALIC ALPHA ITALIC> based no the simulated learner interactions, the average alpha error (the average difference between each item's Predicted alpha at the end of the simulation and its Real alpha) can be considered a good measure of tracking the model's effectiveness in teaching words. Following the same logic as above, the average alpha error of 50 simulation was taken into account. This information not only allows comparison between the computational efficiency of the different algorithm implementations, but also reveals whether improvements in efficiency come at a cost of the agorithm's effectiveness.

    SUBSECTION: Result comparison (Cached recursion)
    The first performance comparison can be observed below, in Table 1. The displayed results are based on simulating learning using a vocabulary list of the size, specified in the first column and tracking the duration of the simulation. The column "total_enc_count" specifies the total number of word encounters, which occured during the simulation and "avg_enc_count" represents the average number of encounters per word. While the total number of encounters remains relatively stable regardless of the vocabulary size, we can see a positive correlation between the average number of encounters per word and the duration of the simulation. This occurs due to the fact that the increasing number of encounters in a word's encounter history increasingly slows down the activation computation, since the algorithm needs to recurse for every single encounter. The real performance comparison, however, is evident in the last two rows of the table, which both use a vocabulary size of 37 for the simulation. The difference between them is in the value of column "cached", which represents whether values were cached during the recursion of the algorithm in order to avoid recalculating of already computed data. As seen by the duration of the simulation, caching the values considerably speeds up the calculation and reduces the number of recursive calls that would be made during the 16<HIGHER TH HIGHER> encounter from 32768 to 17.

    Table 1: test_results_cached_recursion (add number of calls needed for the 16th encounter)

    SUBSECTION: Result comparison (Encounter duration)
    In order to accurately represent learner interaction and record the spacing effect, the simulation needs to advance its internal clock after each word encounter by an amount, resembling how much time an actual learner would take in order to complete the encounter. To achieve this, Formula 4 {Reference: Van Rijn, Van Maanen, and Van Woudenberg, 2009}, which predicts the reaction time of the learner based on an item's activation, was used to calculate the amount of time it would take the learner to start interacting with the system after being exposed to the cue. Since the learning process increases the reaction time, some padding was added in order to adjust the encounter duration to resemble that of a real life learner. The adjustment was based on the results, shown in Table 2 and explained that a too long or too short encounter duration do not accurately reflect the benefit of the spacing effect in the learning process. As the results show, a padding of 3 seconds on top of the predicted reaction time produce the lowest <ITALIC ALPHA ITALIC> error as well as decent simulation duration compared to the rest of the tests.

    Formula 4: Calculate reaction time based on activation
    Table 2: test_results_encounter_duration (change 'writing_time' to 'padding' or sth)

    SUBSECTION: Result comparison (<ITALIC ALPHA ITALIC> adjustment value)
    Another important aspect of the model is how it adjusts the item <ITALIC ALPHA ITALIC>s after each encounter. While some implementations of a spacing effect system use the learner's reaction time in order to calculate an appropriate new value {Reference: Van Rijn, Van Maanen, and Van Woudenberg, 2009}, our implementation uses the item's recall probability as a way of scaling the adjust value and applying it to the item's <ITALIC ALPHA ITALIC> depending on the outcome of the encounter. The <ITALIC ALPHA ITALIC> adjustment value is doubled, because of the fact that the model attempts to present words when they are at around 50% recall probability, which means that most of the time, the actual adjustment value will be applied. The calculation can be seen in the formulas below.

    Formula 3.2_a: Adjusting the <ITALIC ALPHA ITALIC> when a correct answer is given
    Formula 3.2_b: Adjusting the <ITALIC ALPHA ITALIC> when an incorrect answer is given
    
    Tables 3_a and 3_b show that an <ITALIC ALPHA ITALIC> adjust value of 0.02 not only leads to a lower average <ITALIC ALPHA ITALIC> error, but also provides stable results due to the fact that the <ITALIC ALPHA ITALIC> error is not skewed in favor of either the predicted <ITALIC ALPHA ITALIC> or the real one.

    Table 3_a: test_results_alpha_adjust_value (INITIAL TEST)
    Table 3_b: test_results_alpha_adjust_value (SECONDARY TEST)

    The tables also show the results of adjusting the items' <ITALIC ALPHA ITALIC>s after the study sessions is over, which leads to significant increase in <ITALIC ALPHA ITALIC> error and bias.

    SUBSECTION: Result comparison (Cached encounter histories)
    The results of the implementation of the heuristic approach described above can be seen in Table 4. The displayed data can be used to compare the performance of the algorithm when the previous item activations are not cashed and when they are cached and the cache gets updated a various intervals. The first thing to note is that caching the item activations not only provides very similar results in terms of learning effectiveness (as evident by by the similar <ITALIC ALPHA ITALIC> error values and biases), but also significantly improves the computational performance of the algorithm (proved by the impressively shorter simulation duration). The second important aspect of the results is the cache update interval. As already mentioned, even though caching all previous activations improves the algorithm's computational efficiency, if the cache is never updated, there will come a point where the items' <ITALIC ALPHA ITALIC>s have been updated enough for the data in the cache to become outdated and therefore lead to disastrous results. The fact that this claim is not supported by the data could be because each word has an average of 18 encounters and that might not be enough time for the cache to get outdated.
    Keeping in mind that only one item's <ITALIC ALPHA ITALIC> changes after each item interaction, it would be reasonable to update the cache after each encounter (since only one item's activation would need to be recalculated). Table 4, however, also shows that updating the cache after every encounter provides higher <ITALIC ALPHA ITALIC> error and is not as effective at improving the algorithm's performance. The most effective implementation is the one where the cache only gets updated after the study session is over. This helps avoid any unwanted fluctuations in the <ITALIC ALPHA ITALIC>s during the sessions and does not allow for the cache to become out of date. The added benefit of this implementation is that since the cache update happens between study sessions, this does not influence the system's performance while it is in use and does not hinder user interaction.

    Table 4: test_results_cached_history

    SUBSECTION: Result comparison (Learning duration)
    // TODO: show results, say that a lot performed better at learning, but the point of the thesis is performance


5. Possible extensions/improvements (Outlook)



6. Conclusion


    \\ TODO: think about running a simulation on 7 sessions, 4 days apart OR 14 sessions, 2 days apart


APENDIX A: base implementation (basic recursion + calc decay)
